In this project, we tackled the problem of classifying food images by exploring three different machine learning models: support vector machines, convolutional neural networks, and traditional neural networks. The dataset we used was Food-101, which contains 101,000 images of food equally balanced among 101 different categories. 

We began with unsupervised analysis using PCA and feature inspection. PCA revealed that most of the variance was captured by the top 500 components, suggesting that many raw pixel features are redundant and that dimensionality reduction is necessary before classification.

For SVMs, we initially believed that it may be decent in classifying the food images due to its ability to effectively take on high-dimensional inputs. However, from our results, it was clear that given our dataset and some limitations in computation, we were unable to retrieve a meaningful accuracy for this dataset, with the highest only being around 5.6%. Nevertheless, we were able to conclude that an RBF kernel is best out of the three transformations, and regularization can significantly help with results. But, due to the complexity of the images given with varying lighting and angles, SVMs are not the most efficient nor successful model. 

As for neural networks, we also did not get anything meaningful from the results as the accuracy likewise did not exceed 6%. Flattening the images seemed to be too much for the model, as the total number of features exceeded 250,000. Furthermore, increasing the number of layers also proved unhelpful, as performance went down even after adding more dense layers. Thus, we can conclude that this non convolutional neural network is underfitting the data and lacks the complexity to generalize the dataset and capture all the edges and textures. 

With the convolutional neural networks, however, we were able to get slightly more improved performance, with the best model getting a validation accuracy of around 26%. We expect further improvements with deeper architectures and longer training durations, particularly if larger portions of the dataset are used. Nevertheless, CNNs proved to be the best model for this task, as it is able to capture the shapes and patterns in the data. With longer and more extensive training, we believe it has the potential to do incredibly well on this dataset. 

Our results suggest that while traditional models struggle with this task, CNNs offer a promising foundation for food image classification. With more testing and the inclusion of more food categories, this could be generalized to thousands of different foods around the world. This would be of great benefit for many aspects of society, including but not limited to dietary tracking, AI cooking assistants, and restaurant recommendation systems. 
